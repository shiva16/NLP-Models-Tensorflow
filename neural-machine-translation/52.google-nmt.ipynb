{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.utils import shuffle\n",
    "import re\n",
    "import time\n",
    "import collections\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_dataset(words, n_words, atleast=1):\n",
    "    count = [['PAD', 0], ['GO', 1], ['EOS', 2], ['UNK', 3]]\n",
    "    counter = collections.Counter(words).most_common(n_words)\n",
    "    counter = [i for i in counter if i[1] >= atleast]\n",
    "    count.extend(counter)\n",
    "    dictionary = dict()\n",
    "    for word, _ in count:\n",
    "        dictionary[word] = len(dictionary)\n",
    "    data = list()\n",
    "    unk_count = 0\n",
    "    for word in words:\n",
    "        index = dictionary.get(word, 0)\n",
    "        if index == 0:\n",
    "            unk_count += 1\n",
    "        data.append(index)\n",
    "    count[0][1] = unk_count\n",
    "    reversed_dictionary = dict(zip(dictionary.values(), dictionary.keys()))\n",
    "    return data, count, dictionary, reversed_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len from: 500, len to: 500\n"
     ]
    }
   ],
   "source": [
    "with open('english-train', 'r') as fopen:\n",
    "    text_from = fopen.read().lower().split('\\n')[:-1]\n",
    "with open('vietnam-train', 'r') as fopen:\n",
    "    text_to = fopen.read().lower().split('\\n')[:-1]\n",
    "print('len from: %d, len to: %d'%(len(text_from), len(text_to)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab from size: 1935\n",
      "Most common words [(',', 564), ('.', 477), ('the', 368), ('and', 286), ('to', 242), ('of', 220)]\n",
      "Sample data [482, 483, 78, 6, 137, 484, 10, 226, 787, 14] ['rachel', 'pike', ':', 'the', 'science', 'behind', 'a', 'climate', 'headline', 'in']\n"
     ]
    }
   ],
   "source": [
    "concat_from = ' '.join(text_from).split()\n",
    "vocabulary_size_from = len(list(set(concat_from)))\n",
    "data_from, count_from, dictionary_from, rev_dictionary_from = build_dataset(concat_from, vocabulary_size_from)\n",
    "print('vocab from size: %d'%(vocabulary_size_from))\n",
    "print('Most common words', count_from[4:10])\n",
    "print('Sample data', data_from[:10], [rev_dictionary_from[i] for i in data_from[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vocab to size: 1461\n",
      "Most common words [(',', 472), ('.', 430), ('tôi', 283), ('và', 230), ('có', 199), ('chúng', 196)]\n",
      "Sample data [84, 22, 668, 73, 10, 389, 110, 34, 81, 299] ['khoa', 'học', 'đằng', 'sau', 'một', 'tiêu', 'đề', 'về', 'khí', 'hậu']\n"
     ]
    }
   ],
   "source": [
    "concat_to = ' '.join(text_to).split()\n",
    "vocabulary_size_to = len(list(set(concat_to)))\n",
    "data_to, count_to, dictionary_to, rev_dictionary_to = build_dataset(concat_to, vocabulary_size_to)\n",
    "print('vocab to size: %d'%(vocabulary_size_to))\n",
    "print('Most common words', count_to[4:10])\n",
    "print('Sample data', data_to[:10], [rev_dictionary_to[i] for i in data_to[:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "GO = dictionary_from['GO']\n",
    "PAD = dictionary_from['PAD']\n",
    "EOS = dictionary_from['EOS']\n",
    "UNK = dictionary_from['UNK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(text_to)):\n",
    "    text_to[i] += ' EOS'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.util import nest\n",
    "from tensorflow.python.layers.core import Dense\n",
    "\n",
    "def gnmt_residual_fn(inputs, outputs):\n",
    "    def split_input(inp, out):\n",
    "        out_dim = out.get_shape().as_list()[-1]\n",
    "        inp_dim = inp.get_shape().as_list()[-1]\n",
    "        return tf.split(inp, [out_dim, inp_dim - out_dim], axis=-1)\n",
    "    actual_inputs, _ = nest.map_structure(split_input, inputs, outputs)\n",
    "\n",
    "    def assert_shape_match(inp, out):\n",
    "        inp.get_shape().assert_is_compatible_with(out.get_shape())\n",
    "    nest.assert_same_structure(actual_inputs, outputs)\n",
    "    nest.map_structure(assert_shape_match, actual_inputs, outputs)\n",
    "    return nest.map_structure(lambda inp, out: inp + out, actual_inputs, outputs)\n",
    "\n",
    "class GNMTAttentionMultiCell(tf.nn.rnn_cell.MultiRNNCell):\n",
    "\n",
    "    def __init__(self, attention_cell, cells, use_new_attention=True):\n",
    "        cells = [attention_cell] + cells\n",
    "        self.use_new_attention = use_new_attention\n",
    "        super(GNMTAttentionMultiCell, self).__init__(\n",
    "            cells, state_is_tuple=True)\n",
    "\n",
    "    def __call__(self, inputs, state, scope=None):\n",
    "        \"\"\"Run the cell with bottom layer's attention copied to all upper layers.\"\"\"\n",
    "        if not nest.is_sequence(state):\n",
    "            raise ValueError(\n",
    "                \"Expected state to be a tuple of length %d, but received: %s\"\n",
    "                % (len(self.state_size), state))\n",
    "\n",
    "        with tf.variable_scope(scope or \"multi_rnn_cell\"):\n",
    "            new_states = []\n",
    "\n",
    "            with tf.variable_scope(\"cell_0_attention\"):\n",
    "                attention_cell = self._cells[0]\n",
    "                attention_state = state[0]\n",
    "                cur_inp, new_attention_state = attention_cell(\n",
    "                    inputs, attention_state)\n",
    "                new_states.append(new_attention_state)\n",
    "\n",
    "            for i in range(1, len(self._cells)):\n",
    "                with tf.variable_scope(\"cell_%d\" % i):\n",
    "                    cell = self._cells[i]\n",
    "                    cur_state = state[i]\n",
    "\n",
    "                    if self.use_new_attention:\n",
    "                        cur_inp = tf.concat(\n",
    "                            [cur_inp, new_attention_state.attention], -1)\n",
    "                    else:\n",
    "                        cur_inp = tf.concat(\n",
    "                            [cur_inp, attention_state.attention], -1)\n",
    "\n",
    "                    cur_inp, new_state = cell(cur_inp, cur_state)\n",
    "                    new_states.append(new_state)\n",
    "\n",
    "        return cur_inp, tuple(new_states)\n",
    "\n",
    "class Chatbot:\n",
    "    def __init__(self, size_layer, num_layers, embedded_size,\n",
    "                 from_dict_size, to_dict_size, learning_rate, beam_width = 15):\n",
    "        \n",
    "        def cells(size,reuse=False):\n",
    "            return tf.nn.rnn_cell.GRUCell(size,reuse=reuse)\n",
    "        \n",
    "        self.X = tf.placeholder(tf.int32, [None, None])\n",
    "        self.Y = tf.placeholder(tf.int32, [None, None])\n",
    "        self.X_seq_len = tf.count_nonzero(self.X, 1, dtype=tf.int32)\n",
    "        self.Y_seq_len = tf.count_nonzero(self.Y, 1, dtype=tf.int32)\n",
    "        batch_size = tf.shape(self.X)[0]\n",
    "        \n",
    "        encoder_embeddings = tf.Variable(tf.random_uniform([from_dict_size, embedded_size], -1, 1))\n",
    "        decoder_embeddings = tf.Variable(tf.random_uniform([to_dict_size, embedded_size], -1, 1))\n",
    "        encoder_embedded = tf.nn.embedding_lookup(encoder_embeddings, self.X)\n",
    "        main = tf.strided_slice(self.Y, [0, 0], [batch_size, -1], [1, 1])\n",
    "        decoder_input = tf.concat([tf.fill([batch_size, 1], GO), main], 1)\n",
    "        decoder_embedded = tf.nn.embedding_lookup(encoder_embeddings, decoder_input)\n",
    "        \n",
    "        num_residual_layer = num_layers - 2\n",
    "        num_bi_layer = 1\n",
    "        num_ui_layer = num_layers - num_bi_layer\n",
    "\n",
    "        for n in range(num_bi_layer):\n",
    "            (out_fw, out_bw), (state_fw, state_bw) = tf.nn.bidirectional_dynamic_rnn(\n",
    "                cell_fw = cells(size_layer),\n",
    "                cell_bw = cells(size_layer),\n",
    "                inputs = encoder_embedded,\n",
    "                sequence_length = self.X_seq_len,\n",
    "                dtype = tf.float32,\n",
    "                scope = 'bidirectional_rnn_%d'%(n))\n",
    "            encoder_embedded = tf.concat((out_fw, out_bw), 2)\n",
    "        \n",
    "        gru_cells = tf.nn.rnn_cell.MultiRNNCell([cells(size_layer) for _ in range(num_ui_layer)])\n",
    "        encoder_outputs, encoder_state = tf.nn.dynamic_rnn(\n",
    "                gru_cells,\n",
    "                encoder_embedded,\n",
    "                dtype=tf.float32,\n",
    "                sequence_length=self.X_seq_len)\n",
    "        \n",
    "        encoder_state = (state_bw,) + (\n",
    "                (encoder_state,) if num_ui_layer == 1 else encoder_state)\n",
    "        \n",
    "        decoder_cells = []\n",
    "        for n in range(num_layers):\n",
    "            cell = cells(size_layer)\n",
    "            if (n >= num_layers - num_residual_layer):\n",
    "                cell = tf.nn.rnn_cell.ResidualWrapper(cell, residual_fn = gnmt_residual_fn)\n",
    "            decoder_cells.append(cell)\n",
    "        attention_cell = decoder_cells.pop(0)\n",
    "        to_dense = tf.layers.Dense(to_dict_size)\n",
    "        \n",
    "        with tf.variable_scope('decode'):\n",
    "            attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
    "                num_units = size_layer, \n",
    "                memory = encoder_outputs,\n",
    "                memory_sequence_length = self.X_seq_len)\n",
    "            att_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                cell = attention_cell,\n",
    "                attention_mechanism = attention_mechanism,\n",
    "                attention_layer_size = None,\n",
    "                alignment_history = True,\n",
    "                output_attention = False)\n",
    "            gcell = GNMTAttentionMultiCell(att_cell, decoder_cells)\n",
    "            \n",
    "            self.initial_state = tuple(\n",
    "                zs.clone(cell_state=es)\n",
    "                if isinstance(zs, tf.contrib.seq2seq.AttentionWrapperState) else es\n",
    "                for zs, es in zip(\n",
    "                    gcell.zero_state(batch_size, dtype=tf.float32), encoder_state))\n",
    "            \n",
    "            training_helper = tf.contrib.seq2seq.TrainingHelper(\n",
    "                decoder_embedded,\n",
    "                self.Y_seq_len,\n",
    "                time_major = False\n",
    "            )\n",
    "            training_decoder = tf.contrib.seq2seq.BasicDecoder(\n",
    "                cell = gcell,\n",
    "                helper = training_helper,\n",
    "                initial_state = self.initial_state,\n",
    "                output_layer = to_dense)\n",
    "            training_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                decoder = training_decoder,\n",
    "                impute_finished = True,\n",
    "                maximum_iterations = tf.reduce_max(self.Y_seq_len))\n",
    "            self.training_logits = training_decoder_output.rnn_output\n",
    "            \n",
    "        with tf.variable_scope('decode', reuse=True):\n",
    "            encoder_out_tiled = tf.contrib.seq2seq.tile_batch(encoder_outputs, beam_width)\n",
    "            encoder_state_tiled = tf.contrib.seq2seq.tile_batch(encoder_state, beam_width)\n",
    "            X_seq_len_tiled = tf.contrib.seq2seq.tile_batch(self.X_seq_len, beam_width)\n",
    "            \n",
    "            attention_mechanism = tf.contrib.seq2seq.BahdanauAttention(\n",
    "                num_units = size_layer, \n",
    "                memory = encoder_out_tiled,\n",
    "                memory_sequence_length = X_seq_len_tiled)\n",
    "            att_cell = tf.contrib.seq2seq.AttentionWrapper(\n",
    "                cell = attention_cell,\n",
    "                attention_mechanism = attention_mechanism,\n",
    "                attention_layer_size = None,\n",
    "                alignment_history = False,\n",
    "                output_attention = False)\n",
    "            gcell = GNMTAttentionMultiCell(att_cell, decoder_cells)\n",
    "            \n",
    "            self.initial_state = tuple(\n",
    "                zs.clone(cell_state=es)\n",
    "                if isinstance(zs, tf.contrib.seq2seq.AttentionWrapperState) else es\n",
    "                for zs, es in zip(\n",
    "                    gcell.zero_state(batch_size * beam_width, dtype=tf.float32), encoder_state_tiled))\n",
    "            \n",
    "            predicting_decoder = tf.contrib.seq2seq.BeamSearchDecoder(\n",
    "                cell = gcell,\n",
    "                embedding = decoder_embeddings,\n",
    "                start_tokens = tf.tile(tf.constant([GO], dtype=tf.int32), [batch_size]),\n",
    "                end_token = EOS,\n",
    "                initial_state = self.initial_state,\n",
    "                beam_width = beam_width,\n",
    "                output_layer = to_dense,\n",
    "                length_penalty_weight = 0.0)\n",
    "            predicting_decoder_output, _, _ = tf.contrib.seq2seq.dynamic_decode(\n",
    "                decoder = predicting_decoder,\n",
    "                impute_finished = False,\n",
    "                maximum_iterations = 2 * tf.reduce_max(self.X_seq_len))\n",
    "            self.predicting_ids = predicting_decoder_output.predicted_ids[:, :, 0]\n",
    "            \n",
    "        masks = tf.sequence_mask(self.Y_seq_len, tf.reduce_max(self.Y_seq_len), dtype=tf.float32)\n",
    "        self.cost = tf.contrib.seq2seq.sequence_loss(logits = self.training_logits,\n",
    "                                                     targets = self.Y,\n",
    "                                                     weights = masks)\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate).minimize(self.cost)\n",
    "        y_t = tf.argmax(self.training_logits,axis=2)\n",
    "        y_t = tf.cast(y_t, tf.int32)\n",
    "        self.prediction = tf.boolean_mask(y_t, masks)\n",
    "        mask_label = tf.boolean_mask(self.Y, masks)\n",
    "        correct_pred = tf.equal(self.prediction, mask_label)\n",
    "        correct_index = tf.cast(correct_pred, tf.float32)\n",
    "        self.accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_layer = 128\n",
    "num_layers = 4\n",
    "embedded_size = 128\n",
    "learning_rate = 0.001\n",
    "batch_size = 16\n",
    "epoch = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "model = Chatbot(size_layer, num_layers, embedded_size, len(dictionary_from), \n",
    "                len(dictionary_to), learning_rate,batch_size)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str_idx(corpus, dic):\n",
    "    X = []\n",
    "    for i in corpus:\n",
    "        ints = []\n",
    "        for k in i.split():\n",
    "            ints.append(dic.get(k,UNK))\n",
    "        X.append(ints)\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = str_idx(text_from, dictionary_from)\n",
    "Y = str_idx(text_to, dictionary_to)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sentence_batch(sentence_batch, pad_int):\n",
    "    padded_seqs = []\n",
    "    seq_lens = []\n",
    "    max_sentence_len = max([len(sentence) for sentence in sentence_batch])\n",
    "    for sentence in sentence_batch:\n",
    "        padded_seqs.append(sentence + [pad_int] * (max_sentence_len - len(sentence)))\n",
    "        seq_lens.append(len(sentence))\n",
    "    return padded_seqs, seq_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, avg loss: 6.548914, avg accuracy: 0.050564\n",
      "epoch: 2, avg loss: 6.038840, avg accuracy: 0.083646\n",
      "epoch: 3, avg loss: 5.889536, avg accuracy: 0.107929\n",
      "epoch: 4, avg loss: 5.777255, avg accuracy: 0.116488\n",
      "epoch: 5, avg loss: 5.656294, avg accuracy: 0.129913\n",
      "epoch: 6, avg loss: 5.469441, avg accuracy: 0.143000\n",
      "epoch: 7, avg loss: 5.211525, avg accuracy: 0.166089\n",
      "epoch: 8, avg loss: 4.946451, avg accuracy: 0.186357\n",
      "epoch: 9, avg loss: 4.646811, avg accuracy: 0.206599\n",
      "epoch: 10, avg loss: 4.357532, avg accuracy: 0.233228\n",
      "epoch: 11, avg loss: 4.068010, avg accuracy: 0.261730\n",
      "epoch: 12, avg loss: 3.767738, avg accuracy: 0.296694\n",
      "epoch: 13, avg loss: 3.490741, avg accuracy: 0.335230\n",
      "epoch: 14, avg loss: 3.218014, avg accuracy: 0.376315\n",
      "epoch: 15, avg loss: 2.915447, avg accuracy: 0.438789\n",
      "epoch: 16, avg loss: 2.652851, avg accuracy: 0.481870\n",
      "epoch: 17, avg loss: 2.396472, avg accuracy: 0.532073\n",
      "epoch: 18, avg loss: 2.145722, avg accuracy: 0.581913\n",
      "epoch: 19, avg loss: 1.923750, avg accuracy: 0.628581\n",
      "epoch: 20, avg loss: 1.705201, avg accuracy: 0.675990\n"
     ]
    }
   ],
   "source": [
    "for i in range(epoch):\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "    X, Y = shuffle(X, Y)\n",
    "    for k in range(0, len(X), batch_size):\n",
    "        index = min(k + batch_size, len(X))\n",
    "        batch_x, seq_x = pad_sentence_batch(X[k: index], PAD)\n",
    "        batch_y, seq_y = pad_sentence_batch(Y[k: index], PAD)\n",
    "        predicted, accuracy, loss, _ = sess.run([model.predicting_ids,\n",
    "                                      model.accuracy, model.cost, model.optimizer], \n",
    "                                      feed_dict={model.X:batch_x,\n",
    "                                                model.Y:batch_y})\n",
    "        total_loss += loss\n",
    "        total_accuracy += accuracy\n",
    "    total_loss /= (len(X) / batch_size)\n",
    "    total_accuracy /= (len(X) / batch_size)\n",
    "    print('epoch: %d, avg loss: %f, avg accuracy: %f'%(i+1, total_loss, total_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "row 1\n",
      "QUESTION: so we were pretty reassured by this .\n",
      "REAL ANSWER: nên chúng tôi khá an tâm .\n",
      "PREDICTED ANSWER: nên chúng chúng rất chúng thực . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . \n",
      "\n",
      "row 2\n",
      "QUESTION: it &apos;s a lot of water-based materials like concrete , water-based paint , mud , and also some refined oils as well .\n",
      "REAL ANSWER: còn rất nhiều chất có nước như bê tông , sơn có chứa nước , bùn , và một số loại dầu tinh chế nữa .\n",
      "PREDICTED ANSWER: như rất , như chống , như chống , như rất , rất , nó tông chống , \n",
      "\n",
      "row 3\n",
      "QUESTION: so the effect that this stroke could have on mario &apos;s body could be the fact that he couldn &apos;t be able to control the left side of his body .\n",
      "REAL ANSWER: hậu quả của cú đột quỵ đối với cơ thể của mario có thể tệ đến mức mario sẽ không còn có thể sử dụng được phần cơ thể bên trái nữa .\n",
      "PREDICTED ANSWER: hậu quỵ , này bạn ra ra , nào ra , nào ra , nào ra , nào ra , nào ra , nào ra , nào ra , nào ra , nào ra , này . là , , nào ra , \n",
      "\n",
      "row 4\n",
      "QUESTION: rachel pike : the science behind a climate headline\n",
      "REAL ANSWER: khoa học đằng sau một tiêu đề về khí hậu\n",
      "PREDICTED ANSWER: khoa khoa thuật nào ra , \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(batch_x)):\n",
    "    print('row %d'%(i+1))\n",
    "    print('QUESTION:',' '.join([rev_dictionary_from[n] for n in batch_x[i] if n not in [0,1,2,3]]))\n",
    "    print('REAL ANSWER:',' '.join([rev_dictionary_to[n] for n in batch_y[i] if n not in[0,1,2,3]]))\n",
    "    print('PREDICTED ANSWER:',' '.join([rev_dictionary_to[n] for n in predicted[i] if n not in[0,1,2,3]]),'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
