{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from utils import *\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_causal(x, size, rate):\n",
    "    pad_len = (size - 1) * rate\n",
    "    return tf.pad(x, [[0, 0], [pad_len, 0], [0, 0]])\n",
    "\n",
    "class Wavenet:\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_layers,\n",
    "        size_layers,\n",
    "        num_blocks = 3,\n",
    "        block_size = 128,\n",
    "        dropout = 1.0,\n",
    "    ):\n",
    "        self.X = tf.placeholder(tf.int32, (None, None))\n",
    "        lookup_table = tf.get_variable(\n",
    "            'lookup_table',\n",
    "            dtype = tf.float32,\n",
    "            shape = [len(vocab), size_layers],\n",
    "            initializer = tf.truncated_normal_initializer(\n",
    "                mean = 0.0, stddev = 0.01\n",
    "            ),\n",
    "        )\n",
    "        lookup_table = tf.concat(\n",
    "            (tf.zeros(shape = [1, size_layers]), lookup_table[1:, :]), 0\n",
    "        )\n",
    "        forward = tf.nn.embedding_lookup(lookup_table, self.X)\n",
    "        self.Y = tf.placeholder(tf.float32, (None, None, n_mels * resampled))\n",
    "        self.decoder_inputs = tf.concat(\n",
    "            (tf.zeros_like(self.Y[:, :1, :]), self.Y[:, :-1, :]), 1\n",
    "        )\n",
    "        self.decoder_inputs = self.decoder_inputs[:, :, -n_mels:]\n",
    "        print(self.decoder_inputs)\n",
    "        self.Z = tf.placeholder(\n",
    "            tf.float32, (None, None, fourier_window_size // 2 + 1)\n",
    "        )\n",
    "        \n",
    "        def residual_block(x, size, rate, block):\n",
    "            with tf.variable_scope('block_%d_%d' % (block, rate), reuse = False):\n",
    "                conv_filter = tf.layers.conv1d(\n",
    "                    x,\n",
    "                    x.shape[2] // 4,\n",
    "                    kernel_size = size,\n",
    "                    strides = 1,\n",
    "                    padding = 'same',\n",
    "                    dilation_rate = rate,\n",
    "                    activation = tf.nn.tanh,\n",
    "                )\n",
    "                conv_gate = tf.layers.conv1d(\n",
    "                    x,\n",
    "                    x.shape[2] // 4,\n",
    "                    kernel_size = size,\n",
    "                    strides = 1,\n",
    "                    padding = 'same',\n",
    "                    dilation_rate = rate,\n",
    "                    activation = tf.nn.sigmoid,\n",
    "                )\n",
    "                out = tf.multiply(conv_filter, conv_gate)\n",
    "                out = tf.layers.conv1d(\n",
    "                    out,\n",
    "                    block_size,\n",
    "                    kernel_size = 1,\n",
    "                    strides = 1,\n",
    "                    padding = 'same',\n",
    "                    activation = tf.nn.tanh,\n",
    "                )\n",
    "                return tf.add(x, out), out\n",
    "        \n",
    "        with tf.variable_scope('encode', reuse = False):\n",
    "            forward = tf.layers.conv1d(forward, block_size, kernel_size = 1, strides = 1, padding = 'SAME')\n",
    "            zeros = tf.zeros_like(forward)\n",
    "            for i in range(num_blocks):\n",
    "                for r in [1, 2, 4, 8, 16]:\n",
    "                    forward, s = residual_block(forward, size=7, rate=r, block=i)\n",
    "                    zeros = tf.add(zeros,s)\n",
    "            forward = tf.layers.conv1d(forward, block_size, kernel_size = 1, strides = 1, padding = 'SAME')\n",
    "            encoded = tf.layers.conv1d(forward, n_mels, kernel_size = 1, \n",
    "                                          strides = 1, padding = 'SAME')\n",
    "            encoded = tf.reduce_mean(encoded,axis=1,keepdims=True)\n",
    "            \n",
    "        with tf.variable_scope('y_hat', reuse = False):\n",
    "            encoded_tile = tf.tile(encoded, [1, tf.shape(self.decoder_inputs)[1],1])\n",
    "            self.decoder_inputs = tf.multiply(self.decoder_inputs, encoded_tile)\n",
    "            forward = tf.layers.conv1d(self.decoder_inputs, block_size, \n",
    "                                       kernel_size = 1, strides = 1, padding = 'SAME')\n",
    "            zeros = tf.zeros_like(forward)\n",
    "            for i in range(num_blocks):\n",
    "                for r in [1, 2, 4, 8, 16]:\n",
    "                    forward, s = residual_block(forward, size=7, rate=r, block=i)\n",
    "                    zeros = tf.add(zeros,s)\n",
    "            forward = tf.layers.conv1d(forward, block_size, kernel_size = 1, strides = 1, padding = 'SAME')\n",
    "            self.Y_hat = tf.layers.conv1d(forward, n_mels * resampled, kernel_size = 1, \n",
    "                                          strides = 1, padding = 'SAME')\n",
    "        \n",
    "        \n",
    "        with tf.variable_scope('z_hat', reuse = False):\n",
    "            forward = tf.reshape(\n",
    "                self.Y_hat, [tf.shape(self.Y_hat)[0], -1, n_mels]\n",
    "            )\n",
    "            forward = tf.layers.conv1d(forward, size_layers, kernel_size = 1, strides = 1, padding = 'SAME')\n",
    "            zeros = tf.zeros_like(forward)\n",
    "            for i in range(num_blocks):\n",
    "                for r in [1, 2, 4, 8, 16]:\n",
    "                    forward, s = residual_block(forward, size=7, rate=r, block=i)\n",
    "                    zeros = tf.add(zeros,s)\n",
    "            forward = tf.layers.conv1d(forward, block_size, kernel_size = 1, strides = 1, padding = 'SAME')\n",
    "            self.Z_hat = tf.layers.conv1d(forward, 1 + fourier_window_size // 2, kernel_size = 1, \n",
    "                                          strides = 1, padding = 'SAME')\n",
    "        \n",
    "        self.loss1 = tf.reduce_mean(tf.abs(self.Y_hat - self.Y))\n",
    "        self.loss2 = tf.reduce_mean(tf.abs(self.Z_hat - self.Z))\n",
    "        self.loss = self.loss1 + self.loss2\n",
    "        self.lr = 1e-3\n",
    "        self.optimizer = tf.train.AdamOptimizer(\n",
    "            learning_rate = self.lr\n",
    "        ).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"strided_slice_3:0\", shape=(?, ?, 80), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "size_layers = 128\n",
    "learning_rate = 1e-3\n",
    "num_layers = 2\n",
    "\n",
    "model = Wavenet(num_layers, size_layers)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, lengths, texts, raw_texts = [], [], [], []\n",
    "text_files = [f for f in os.listdir('mel') if f.endswith('.npy')]\n",
    "for fpath in text_files:\n",
    "    with open('%s/%s' % (path, fpath.replace('npy', 'txt'))) as fopen:\n",
    "        text = fopen.read()\n",
    "    paths.append(fpath.replace('.npy', ''))\n",
    "    text = text_normalize(text)\n",
    "    raw_texts.append(text)\n",
    "    text = text + 'E'\n",
    "    texts.append(np.array([char2idx[char] for char in text], np.int32))\n",
    "    lengths.append(len(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['YAF_burn_neutral', 'YAF_lose_happy'],\n",
       " [18, 18],\n",
       " [array([21,  3, 27,  2, 22, 10,  7,  2, 25, 17, 20,  6,  2,  4, 23, 20, 16,\n",
       "          1], dtype=int32),\n",
       "  array([21,  3, 27,  2, 22, 10,  7,  2, 25, 17, 20,  6,  2, 14, 17, 21,  7,\n",
       "          1], dtype=int32)])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths[:2], lengths[:2], texts[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dynamic_batching(paths):\n",
    "    files, max_y, max_z = [], 0, 0\n",
    "    for n in range(len(paths)):\n",
    "        files.append(get_cached(paths[n]))\n",
    "        if files[-1][0].shape[0] > max_y:\n",
    "            max_y = files[-1][0].shape[0]\n",
    "        if files[-1][1].shape[0] > max_z:\n",
    "            max_z = files[-1][1].shape[0]\n",
    "    return files, max_y, max_z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "minibatch loop: 100%|██████████| 88/88 [00:20<00:00,  3.29it/s, cost=0.0973]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:15<00:00,  5.71it/s, cost=0.0715]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:15<00:00,  5.77it/s, cost=0.0651]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.73it/s, cost=0.0631]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.67it/s, cost=0.06]  \n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.73it/s, cost=0.058] \n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.68it/s, cost=0.0557]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.69it/s, cost=0.0555]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:15<00:00,  5.75it/s, cost=0.0526]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.72it/s, cost=0.0524]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.73it/s, cost=0.0501]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.68it/s, cost=0.0503]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.74it/s, cost=0.049] \n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.76it/s, cost=0.0484]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.76it/s, cost=0.0474]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:15<00:00,  5.78it/s, cost=0.0467]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:15<00:00,  5.77it/s, cost=0.0464]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.69it/s, cost=0.0464]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:15<00:00,  5.75it/s, cost=0.0455]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.74it/s, cost=0.0456]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.74it/s, cost=0.0448]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:15<00:00,  5.79it/s, cost=0.044] \n",
      "minibatch loop: 100%|██████████| 88/88 [00:15<00:00,  5.75it/s, cost=0.0428]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.83it/s, cost=0.043] \n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.71it/s, cost=0.0427]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.70it/s, cost=0.0417]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:15<00:00,  5.70it/s, cost=0.0411]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:16<00:00,  5.67it/s, cost=0.042] \n",
      "minibatch loop: 100%|██████████| 88/88 [00:15<00:00,  5.77it/s, cost=0.0411]\n",
      "minibatch loop: 100%|██████████| 88/88 [00:15<00:00,  5.76it/s, cost=0.0405]\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 30\n",
    "for i in range(EPOCH):\n",
    "    pbar = tqdm(range(0, len(paths), batch_size), desc = 'minibatch loop')\n",
    "    for k in pbar:\n",
    "        index = min(k + batch_size, len(paths))\n",
    "        files, max_y, max_z = dynamic_batching(paths[k:index])\n",
    "        max_x = max(lengths[k:index])\n",
    "        batch_x = np.zeros((batch_size, max_x))\n",
    "        batch_y = np.zeros((batch_size, max_y, n_mels * resampled))\n",
    "        batch_z = np.zeros((batch_size, max_z, fourier_window_size // 2 + 1))\n",
    "        for n in range(len(files)):\n",
    "            batch_x[n, :] = np.pad(\n",
    "                texts[k + n],\n",
    "                ((0, max_x - texts[k + n].shape[0])),\n",
    "                mode = 'constant',\n",
    "            )\n",
    "            batch_y[n, :, :] = np.pad(\n",
    "                files[n][0],\n",
    "                ((0, max_y - files[n][0].shape[0]), (0, 0)),\n",
    "                mode = 'constant',\n",
    "            )\n",
    "            batch_z[n, :, :] = np.pad(\n",
    "                files[n][1],\n",
    "                ((0, max_z - files[n][1].shape[0]), (0, 0)),\n",
    "                mode = 'constant',\n",
    "            )\n",
    "        _, cost = sess.run(\n",
    "            [model.optimizer, model.loss],\n",
    "            feed_dict = {model.X: batch_x, model.Y: batch_y, model.Z: batch_z},\n",
    "        )\n",
    "        pbar.set_postfix(cost = cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 70.81it/s]\n"
     ]
    }
   ],
   "source": [
    "y_hat = np.zeros((1, 50, n_mels * resampled), np.float32)\n",
    "for j in tqdm(range(50)):\n",
    "    _y_hat = sess.run(model.Y_hat, {model.X: [texts[0]], model.Y: y_hat})\n",
    "    y_hat[:, j, :] = _y_hat[:, j, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mags = sess.run(model.Z_hat, {model.Y_hat: y_hat})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio = spectrogram2wav(mags[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saving: say the word burn\n"
     ]
    }
   ],
   "source": [
    "from scipy.io.wavfile import write\n",
    "print('saving: %s'%(raw_texts[0]))\n",
    "write(os.path.join('test.wav'), sample_rate, audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
